19,2 tỷ tài liệu của Yahoo là không chính xác
Những thắc mắc về quy mô của web, vốn được coi là không bao giờ có thể trả lời, lại trở thành tâm điểm tuần qua khi hãng dịch vụ trực tuyến lớn nhất thế giới tuyên bố sở hữu số tài liệu trong danh mục tìm kiếm gần như gấp đôi Google.
"Ông hàng xóm" tại California (Mỹ) cho rằng thông tin mà Yahoo đưa ra là không chắc chắn. Sergey Brin, đồng sáng lập Google, nghi ngờ phương pháp thống kê của đối thủ và khẳng định kết quả này đã bị thổi phồng bởi những bản sao khác nhau của cùng một cơ sở dữ liệu.
Jean Veronis, chuyên gia ngôn ngữ tại Pháp, cũng nhận định những tài liệu tham chiếu bằng tiếng Pháp của Yahoo dường như đã làm tăng số dữ liệu mà hãng thu nhận được. "Điều này đơn giản cho thấy Yahoo láu cá hơn đối thủ trong việc sắp xếp danh mục tìm kiếm", Veronis nói.
"Sự toàn diện của bất cứ công cụ tìm kiếm nào cũng phải được đo bằng những trang web thực, xuất hiện trong kết quả tìm kiếm và được xác định là tồn tại duy nhất", Brin nói. "Chúng tôi đánh giá kích thước mục lục dựa trên ba tiêu chí này".
Nhưng lãnh đạo Yahoo vẫn giữ vững quan điểm của họ. "Con số tài liệu đưa ra là chính xác", Jeff Weiner, Phó giám đốc bộ phận tìm kiếm và tiếp thị của Yahoo, phát biểu. "Chúng tôi tự hào về thành quả mà kỹ sư và các nhà khoa học của hãng đã đạt được. Hãng sẽ tiếp tục làm hài lòng khách hàng khi mang lại chất lượng và khả năng tìm kiếm cao nhất".
Tuy nhiên, hôm qua, các chuyên gia nghiên cứu tại Trung tâm ứng dụng siêu máy tính quốc gia Mỹ đã tiến hành thí nghiệm nhằm xác minh tính đúng đắn của vấn đề. Họ chạy 10.012 câu lệnh ngẫu nhiên trên hai công cụ tìm kiếm và nhận thấy trung bình Google cho kết quả cao hơn 166,9% so với Yahoo. Chỉ có 3% trong số các trường hợp Yahoo hiển thị nhiều trang web hơn. Nhóm nghiên cứu khẳng định tuyên bố của Yahoo là không chính xác.
Giới quan sát cho rằng tranh cãi này không khác gì đại học Harvard và Yale so đo với nhau xem trường nào sở hữu nhiều sách trong thư viện hơn. "Danh mục không phải là vấn đề quan trọng mà khả năng tìm kiếm đúng theo yêu cầu mới là điều đáng lưu tâm", Gary Stein, chuyên gia phân tích của Jupiter Research, khẳng định.
Công cụ tìm kiếm sử dụng chương trình Web Crawler để dò tài liệu trên Internet một cách hệ thống và lưu chúng trong danh mục theo chủ đề riêng, để cung cấp hàng trăm câu trả lời chỉ trong 1 giây khi người sử dụng nhập từ khoá, ví dụ như "Britney Spears" hay "chip lõi kép"... Cả hai hãng đều không tiết lộ cụ thể các thuật toán xây dựng phần mềm thu thập thông tin của mình. 

